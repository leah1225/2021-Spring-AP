{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Analytic Programming\n",
    "\n",
    "> Homework 6: Analytic Programming, NTU, Spring, 2021.\n",
    "\n",
    "Kuo, Yao-Jen <yaojenkuo@ntu.edu.tw> from [DATAINPOINT](https://www.datainpoint.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Instructions\n",
    "\n",
    "- We've imported necessary modules/libraries at the beginning of each exercise.\n",
    "- We've put necessary files(if any) in the working directory of each exercise.\n",
    "- We've defined the names of functions/inputs/arguments for you.\n",
    "- Write down your solution between the comments `### BEGIN SOLUTION` and `### END SOLUTION`.\n",
    "- Running tests to see if your solutions are right: Kernel -> Restart & Run All -> Restart and Run All Cells.\n",
    "- You can run tests after each question or after finishing all questions.\n",
    "- REMEMBER to upload your `.ipynb` file to [CEIBA](https://ceiba.ntu.edu.tw/) before 2021-06-11 20:59:59 when you are done running tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Define a function named `import_csv_files` that is able to import 4 given csv files `05-25-2021.csv`, `time_series_covid19_confirmed_global.csv`, `time_series_covid19_deaths_global.csv`, and `UID_ISO_FIPS_LookUp_Table.csv` as 4 pandas DataFrames.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a tuple of length 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_files():\n",
    "    \"\"\"\n",
    "    >>> daily_report, time_series_confirmed, time_series_deaths, lookup_table = import_csv_files()\n",
    "    >>> type(daily_report)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> daily_report.shape \n",
    "    (3983, 14)\n",
    "    >>> type(time_series_confirmed)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> time_series_confirmed.shape\n",
    "    (275, 494)\n",
    "    >>> type(time_series_deaths)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> time_series_deaths.shape\n",
    "    (275, 494)\n",
    "    >>> type(lookup_table)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> lookup_table.shape\n",
    "    (4193, 12)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    daily_report = pd.read_csv('05-25-2021.csv')\n",
    "    time_series_confirmed = pd.read_csv('time_series_covid19_confirmed_global.csv')\n",
    "    time_series_deaths = pd.read_csv('time_series_covid19_deaths_global.csv')\n",
    "    lookup_table = pd.read_csv('UID_ISO_FIPS_LookUp_Table.csv')\n",
    "    \n",
    "    return daily_report, time_series_confirmed, time_series_deaths, lookup_table\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Define a function named `find_country_names_with_asterisk` that is able to retrieve the observations with an asterisk `*` from `UID_ISO_FIPS_LookUp_Table.csv`.\n",
    "\n",
    "- Expected inputs: a CSV file `UID_ISO_FIPS_LookUp_Table.csv`.\n",
    "- Expected outputs: a (3, 12) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_country_names_with_asterisk(csv_file_path):\n",
    "    \"\"\"\n",
    "    >>> country_names_with_asterisk = find_country_names_with_asterisk('UID_ISO_FIPS_LookUp_Table.csv')\n",
    "    >>> type(country_names_with_asterisk)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> country_names_with_asterisk.shape\n",
    "    (3, 12)\n",
    "    >>> print(country_names_with_asterisk)\n",
    "           UID iso2 iso3  code3  FIPS Admin2    Province_State Country_Region  \\\n",
    "    659    158   TW  TWN  158.0   NaN    NaN               NaN        Taiwan*   \n",
    "    673  80404   UA  UKR  804.0   NaN    NaN  Crimea Republic*        Ukraine   \n",
    "    689  80420   UA  UKR  804.0   NaN    NaN       Sevastopol*        Ukraine   \n",
    "\n",
    "             Lat     Long_               Combined_Key  Population  \n",
    "    659  23.7000  121.0000                    Taiwan*  23816775.0  \n",
    "    673  45.2835   34.2008  Crimea Republic*, Ukraine   1913731.0  \n",
    "    689  44.6054   33.5220       Sevastopol*, Ukraine    443211.0\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    lookup_table = pd.read_csv(csv_file_path)\n",
    "    return lookup_table[lookup_table['Combined_Key'].str.contains('\\*')]\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Define a function named `remove_asterisk_in_dataframe` that is able to remove the asterisks given after importing `UID_ISO_FIPS_LookUp_Table.csv`.\n",
    "\n",
    "- Expected inputs: a CSV file `UID_ISO_FIPS_LookUp_Table.csv`.\n",
    "- Expected outputs: a (4193, 12) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_asterisk_in_dataframe(csv_file_path):\n",
    "    \"\"\"\n",
    "    >>> asterisk_removed_dataframe = remove_asterisk_in_dataframe('UID_ISO_FIPS_LookUp_Table.csv')\n",
    "    >>> type(asterisk_removed_dataframe)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> asterisk_removed_dataframe.shape\n",
    "    (4193, 12)\n",
    "    >>> twn_ukr = asterisk_removed_dataframe[asterisk_removed_dataframe['UID'].isin([158, 80404, 80420])]\n",
    "    >>> print(twn_ukr)\n",
    "           UID iso2 iso3  code3  FIPS Admin2   Province_State Country_Region  \\\n",
    "    659    158   TW  TWN  158.0   NaN    NaN              NaN         Taiwan   \n",
    "    673  80404   UA  UKR  804.0   NaN    NaN  Crimea Republic        Ukraine   \n",
    "    689  80420   UA  UKR  804.0   NaN    NaN       Sevastopol        Ukraine   \n",
    "\n",
    "             Lat     Long_              Combined_Key  Population  \n",
    "    659  23.7000  121.0000                    Taiwan  23816775.0  \n",
    "    673  45.2835   34.2008  Crimea Republic, Ukraine   1913731.0  \n",
    "    689  44.6054   33.5220       Sevastopol, Ukraine    443211.0\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    lookup_table = pd.read_csv(csv_file_path)\n",
    "    lookup_table['Province_State'] = lookup_table['Province_State'].str.replace('*', '')\n",
    "    lookup_table['Country_Region'] = lookup_table['Country_Region'].str.replace('*', '')\n",
    "    lookup_table['Combined_Key'] = lookup_table['Combined_Key'].str.replace('*', '')\n",
    "    return lookup_table\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Define a function named `summarize_by_countries` that is able to sum the number of `Confirmed` and `Deaths` based on `Country_Region` given `05-25-2021.csv`.\n",
    "\n",
    "- Expected inputs: a CSV file `05-25-2021.csv`.\n",
    "- Expected outputs: a (192, 3) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_countries(csv_file_path):\n",
    "    \"\"\"\n",
    "    >>> summary_by_countries = summarize_by_countries('05-25-2021.csv')\n",
    "    >>> type(summary_by_countries)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> summary_by_countries.shape\n",
    "    (192, 3)\n",
    "    >>> print(summary_by_countries)\n",
    "             Country_Region  Confirmed  Deaths\n",
    "    0           Afghanistan      66903    2836\n",
    "    1               Albania     132229    2447\n",
    "    2               Algeria     127361    3433\n",
    "    3               Andorra      13664     127\n",
    "    4                Angola      32933     735\n",
    "    ..                  ...        ...     ...\n",
    "    187             Vietnam       5931      44\n",
    "    188  West Bank and Gaza     306334    3480\n",
    "    189               Yemen       6670    1311\n",
    "    190              Zambia      93428    1271\n",
    "    191            Zimbabwe      38706    1587\n",
    "\n",
    "    [192 rows x 3 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    daily_report = pd.read_csv(csv_file_path)\n",
    "    left_df = pd.DataFrame(daily_report.groupby('Country_Region')['Confirmed'].sum())\n",
    "    right_df = pd.DataFrame(daily_report.groupby('Country_Region')['Deaths'].sum())\n",
    "    return pd.merge(left_df, right_df, on= 'Country_Region').reset_index()\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Define a function named `summarize_by_countries_and_provinces` that is able to sum the number of `Confirmed` and `Deaths` based on both `Country_Region` and `Province_State` given `05-25-2021.csv`.\n",
    "\n",
    "- Expected inputs: a CSV file `05-25-2021.csv`.\n",
    "- Expected outputs: a (593, 4) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_countries_and_provinces(csv_file_path):\n",
    "    \"\"\"\n",
    "    >>> summary_by_countries_and_provinces = summarize_by_countries_and_provinces('05-25-2021.csv')\n",
    "    >>> type(summary_by_countries_and_provinces)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> summary_by_countries_and_provinces.shape\n",
    "    (593, 4)\n",
    "    >>> print(summary_by_countries_and_provinces)\n",
    "         Country_Region                                Province_State  Confirmed  \\\n",
    "    0         Australia                  Australian Capital Territory        124   \n",
    "    1         Australia                               New South Wales       5576   \n",
    "    2         Australia                            Northern Territory        171   \n",
    "    3         Australia                                    Queensland       1611   \n",
    "    4         Australia                               South Australia        750   \n",
    "    ..              ...                                           ...        ...   \n",
    "    588  United Kingdom  Saint Helena, Ascension and Tristan da Cunha          4   \n",
    "    589  United Kingdom                                      Scotland     232661   \n",
    "    590  United Kingdom                      Turks and Caicos Islands       2409   \n",
    "    591  United Kingdom                                       Unknown          0   \n",
    "    592  United Kingdom                                         Wales     212554   \n",
    "\n",
    "         Deaths  \n",
    "    0         3  \n",
    "    1        54  \n",
    "    2         0  \n",
    "    3         7  \n",
    "    4         4  \n",
    "    ..      ...  \n",
    "    588       0  \n",
    "    589    7666  \n",
    "    590      17  \n",
    "    591       0  \n",
    "    592    5566  \n",
    "\n",
    "    [593 rows x 4 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    daily_report = pd.read_csv(csv_file_path)\n",
    "    left_df = daily_report.groupby(['Country_Region', 'Province_State'])['Confirmed'].sum()\n",
    "    right_df = daily_report.groupby(['Country_Region', 'Province_State'])['Deaths'].sum()\n",
    "    return pd.merge(left_df, right_df, on = ['Country_Region', 'Province_State']).reset_index()\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Define a function named `calculate_death_rate_by_countries` according to the following formula given `05-25-2021.csv`.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Death Rate} = \\frac{\\text{Deaths}}{\\text{Confirmed}}\n",
    "\\end{equation}\n",
    "\n",
    "- Expected inputs: a CSV file `05-25-2021.csv`.\n",
    "- Expected outputs: a Series of length 192."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_death_rate_by_countries(csv_file_path):\n",
    "    \"\"\"\n",
    "    >>> death_rate_by_countries = calculate_death_rate_by_countries('05-25-2021.csv')\n",
    "    >>> type(death_rate_by_countries)\n",
    "    pandas.core.series.Series\n",
    "    >>> death_rate_by_countries.size\n",
    "    192\n",
    "    >>> print(death_rate_by_countries)\n",
    "    Country_Region\n",
    "    Vanuatu                  0.250000\n",
    "    MS Zaandam               0.222222\n",
    "    Yemen                    0.196552\n",
    "    Mexico                   0.092491\n",
    "    Sudan                    0.074522\n",
    "                               ...   \n",
    "    Marshall Islands         0.000000\n",
    "    Micronesia               0.000000\n",
    "    Samoa                    0.000000\n",
    "    Saint Kitts and Nevis    0.000000\n",
    "    Holy See                 0.000000\n",
    "    Length: 192, dtype: float64\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    daily_report = pd.read_csv(csv_file_path)\n",
    "    result = daily_report.groupby('Country_Region')['Deaths'].sum() / daily_report.groupby('Country_Region')['Confirmed'].sum()\n",
    "    return result.sort_values(ascending=False)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Define a function named `calculate_confirmed_rate_by_countries` according to the following formula given `05-25-2021.csv` and `UID_ISO_FIPS_LookUp_Table.csv`.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Confirmed Rate} = \\frac{\\text{Confirmed}}{\\text{Population}}\n",
    "\\end{equation}\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a (192, 3) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confirmed_rate_by_countries():\n",
    "    \"\"\"\n",
    "    >>> confirmed_rate_by_countries = calculate_confirmed_rate_by_countries()\n",
    "    >>> type(confirmed_rate_by_countries)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> confirmed_rate_by_countries.shape\n",
    "    (192, 3)\n",
    "    >>> print(confirmed_rate_by_countries)\n",
    "                      Confirmed  Population  Confirmed_Rate\n",
    "    Country_Region                                         \n",
    "    MS Zaandam                9         0.0             inf\n",
    "    Diamond Princess        712         0.0             inf\n",
    "    Andorra               13664     77265.0        0.176846\n",
    "    Montenegro            99358    628062.0        0.158198\n",
    "    Czechia             1658778  10708982.0        0.154896\n",
    "    ...                     ...         ...             ...\n",
    "    Solomon Islands          20    652858.0        0.000031\n",
    "    Samoa                     3    196130.0        0.000015\n",
    "    Vanuatu                   4    292680.0        0.000014\n",
    "    Micronesia                1    113815.0        0.000009\n",
    "    Tanzania                509  59734213.0        0.000009\n",
    "\n",
    "    [192 rows x 3 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    lookup_table = pd.read_csv('UID_ISO_FIPS_LookUp_Table.csv')\n",
    "    daily_report = pd.read_csv('05-25-2021.csv')\n",
    "\n",
    "    population = lookup_table.groupby('Country_Region')['Population'].sum()\n",
    "    confirmed = daily_report.groupby('Country_Region')['Confirmed'].sum()\n",
    "\n",
    "    result = pd.merge(confirmed, population, on = 'Country_Region')\n",
    "    result['Confirmed_Rate'] = result['Confirmed']/result['Population']\n",
    "    return result.sort_values(['Confirmed_Rate'], ascending=False)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Define a function named `transpose_time_series` that is able to transpose `time_series_covid19_confirmed_global.csv` into a long-format DataFrame.\n",
    "\n",
    "- Expected inputs: a CSV file `time_series_covid19_confirmed_global.csv`.\n",
    "- Expected outputs: a (134750, 4) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_time_series(csv_file_path):\n",
    "    \"\"\"\n",
    "    >>> transposed_time_series = transpose_time_series('time_series_covid19_confirmed_global.csv')\n",
    "    >>> type(transposed_time_series)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> transposed_time_series.shape\n",
    "    (134750, 4)\n",
    "    >>> print(transposed_time_series)\n",
    "           Province/State      Country/Region     Date  Confirmed\n",
    "    0                 NaN         Afghanistan  1/22/20          0\n",
    "    1                 NaN             Albania  1/22/20          0\n",
    "    2                 NaN             Algeria  1/22/20          0\n",
    "    3                 NaN             Andorra  1/22/20          0\n",
    "    4                 NaN              Angola  1/22/20          0\n",
    "    ...               ...                 ...      ...        ...\n",
    "    134745            NaN             Vietnam  5/25/21       5931\n",
    "    134746            NaN  West Bank and Gaza  5/25/21     306334\n",
    "    134747            NaN               Yemen  5/25/21       6670\n",
    "    134748            NaN              Zambia  5/25/21      93428\n",
    "    134749            NaN            Zimbabwe  5/25/21      38706\n",
    "\n",
    "    [134750 rows x 4 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    time_series_confirmed = pd.read_csv(csv_file_path)\n",
    "    time_series_confirmed = time_series_confirmed.drop(columns = ['Lat', 'Long'])\n",
    "    idVars = ['Province/State', 'Country/Region']\n",
    "    ts_confirmed_global_long = pd.melt(time_series_confirmed,\n",
    "                                       id_vars = idVars,\n",
    "                                       var_name='Date',\n",
    "                                       value_name='Confirmed')\n",
    "    return ts_confirmed_global_long\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Define a function named `summarize_time_series` that is able to summarize the summation of confirmed and deaths cases by `Country/Region` given `time_series_covid19_confirmed_global.csv` and `time_series_covid19_deaths_global.csv`.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a (94080, 4) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_time_series():\n",
    "    \"\"\"\n",
    "    >>> summarized_time_series = summarize_time_series()\n",
    "    >>> type(summarized_time_series)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> summarized_time_series.shape\n",
    "    (94080, 4)\n",
    "    >>> print(summarized_time_series)\n",
    "          Country/Region       Date  Confirmed  Deaths\n",
    "    0        Afghanistan 2020-01-22          0       0\n",
    "    1        Afghanistan 2020-01-23          0       0\n",
    "    2        Afghanistan 2020-01-24          0       0\n",
    "    3        Afghanistan 2020-01-25          0       0\n",
    "    4        Afghanistan 2020-01-26          0       0\n",
    "    ...              ...        ...        ...     ...\n",
    "    94075       Zimbabwe 2021-05-21      38664    1586\n",
    "    94076       Zimbabwe 2021-05-22      38679    1586\n",
    "    94077       Zimbabwe 2021-05-23      38682    1586\n",
    "    94078       Zimbabwe 2021-05-24      38696    1586\n",
    "    94079       Zimbabwe 2021-05-25      38706    1587\n",
    "\n",
    "    [94080 rows x 4 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    def change_date(d):\n",
    "        month = d[0]\n",
    "        date = d[1]\n",
    "        year = '20'+ d[2]\n",
    "\n",
    "        if len(date) < 2:\n",
    "            date = '0' + date\n",
    "        if len(month) < 2:\n",
    "            month = '0'+ month\n",
    "\n",
    "        return year + '-' + month + '-' + date\n",
    "\n",
    "    # Confirmed\n",
    "    confirmed = transpose_time_series('time_series_covid19_confirmed_global.csv')\n",
    "    confirmed = confirmed.drop(columns = ['Province/State'])\n",
    "    confirmed_num = confirmed.groupby(['Country/Region', 'Date'])['Confirmed'].sum()\n",
    "\n",
    "    # Deaths\n",
    "    deaths = transpose_time_series('time_series_covid19_deaths_global.csv')\n",
    "    deaths = deaths.drop(columns = ['Province/State'])\n",
    "    deaths = deaths.rename(columns = {'Confirmed':'Deaths'})\n",
    "    deaths_num = deaths.groupby(['Country/Region', 'Date'])['Deaths'].sum()\n",
    "\n",
    "    # Merge\n",
    "    result = pd.merge(confirmed_num, deaths_num, on = ['Country/Region', 'Date']).reset_index()\n",
    "    \n",
    "    # change Date format\n",
    "    result['Date'] = result['Date'].str.split('/').map(change_date)\n",
    "    return result.sort_values(['Country/Region', 'Date'])    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Define a function named `calculate_daily_cases_of_taiwan` that is able to calculate the daily cases of Taiwan a DataFrame as expected given `time_series_covid19_confirmed_global.csv` and `time_series_covid19_deaths_global.csv`.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a (490, 5) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_cases_of_taiwan():\n",
    "    \"\"\"\n",
    "    >>> daily_cases_of_taiwan = calculate_daily_cases_of_taiwan()\n",
    "    >>> type(daily_cases_of_taiwan)\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> daily_cases_of_taiwan.shape\n",
    "    (490, 5)\n",
    "    >>> print(daily_cases_of_taiwan)\n",
    "               Country/Region  Confirmed  Deaths  Daily_Confirmed  Daily_Deaths\n",
    "    Date                                                                       \n",
    "    2020-01-22         Taiwan          1       0              NaN           NaN\n",
    "    2020-01-23         Taiwan          1       0              0.0           0.0\n",
    "    2020-01-24         Taiwan          3       0              2.0           0.0\n",
    "    2020-01-25         Taiwan          3       0              0.0           0.0\n",
    "    2020-01-26         Taiwan          4       0              1.0           0.0\n",
    "    ...                   ...        ...     ...              ...           ...\n",
    "    2021-05-21         Taiwan       3139      15            314.0           0.0\n",
    "    2021-05-22         Taiwan       3862      17            723.0           2.0\n",
    "    2021-05-23         Taiwan       4322      23            460.0           6.0\n",
    "    2021-05-24         Taiwan       4917      29            595.0           6.0\n",
    "    2021-05-25         Taiwan       5456      35            539.0           6.0\n",
    "\n",
    "    [490 rows x 5 columns]\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    summarized_time_series = summarize_time_series()\n",
    "    daily_cases_tw = summarized_time_series[summarized_time_series['Country/Region'] == 'Taiwan*'].copy() # deep copy\n",
    "    daily_cases_tw = daily_cases_tw.set_index('Date')\n",
    "    daily_cases_tw['Country/Region'] = daily_cases_tw['Country/Region'].str.replace('*', '') # strip '*'\n",
    "\n",
    "    # Daily_Confirmed  Daily_Deaths\n",
    "    daily_cases_tw['Daily_Confirmed'] = 0.0\n",
    "    daily_cases_tw['Daily_Deaths'] = 0.0\n",
    "\n",
    "    for i in range(1, daily_cases_tw.shape[0]):\n",
    "        comfirmed_plus = float(daily_cases_tw.iloc[i, 1]- daily_cases_tw.iloc[i-1, 1])\n",
    "        deaths_plus = float(daily_cases_tw.iloc[i, 2]- daily_cases_tw.iloc[i-1, 2])\n",
    "        daily_cases_tw.iloc[i, 3] = comfirmed_plus\n",
    "        daily_cases_tw.iloc[i, 4] = deaths_plus\n",
    "\n",
    "    # Day 1\n",
    "    daily_cases_tw.iloc[0, 3] = 'NaN'\n",
    "    daily_cases_tw.iloc[0, 4] = 'NaN'\n",
    "\n",
    "    return daily_cases_tw    \n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Run tests!\n",
    "\n",
    "Kernel -> Restart & Run All. -> Restart And Run All Cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_00_import_csv_files (__main__.TestHomeworkSix) ... ok\n",
      "test_01_find_country_names_with_asterisk (__main__.TestHomeworkSix) ... ok\n",
      "test_02_remove_asterisk_in_dataframe (__main__.TestHomeworkSix) ... ok\n",
      "test_03_summarize_by_countries (__main__.TestHomeworkSix) ... ok\n",
      "test_04_summarize_by_countries_and_provinces (__main__.TestHomeworkSix) ... ok\n",
      "test_05_calculate_death_rate_by_countries (__main__.TestHomeworkSix) ... ok\n",
      "test_06_calculate_confirmed_rate_by_countries (__main__.TestHomeworkSix) ... ok\n",
      "test_07_transpose_time_series (__main__.TestHomeworkSix) ... ok\n",
      "test_08_summarize_time_series (__main__.TestHomeworkSix) ... ok\n",
      "test_09_calculate_daily_cases_of_taiwan (__main__.TestHomeworkSix) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 2.131s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestHomeworkSix(unittest.TestCase):\n",
    "    def test_00_import_csv_files(self):\n",
    "        daily_report, time_series_confirmed, time_series_deaths, lookup_table = import_csv_files()\n",
    "        self.assertIsInstance(daily_report, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(daily_report.shape, (3983, 14))\n",
    "        self.assertIsInstance(time_series_confirmed, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(time_series_confirmed.shape, (275, 494))\n",
    "        self.assertIsInstance(time_series_deaths, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(time_series_deaths.shape, (275, 494))\n",
    "        self.assertIsInstance(lookup_table, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(lookup_table.shape, (4193, 12))\n",
    "    def test_01_find_country_names_with_asterisk(self):\n",
    "        country_names_with_asterisk = find_country_names_with_asterisk('UID_ISO_FIPS_LookUp_Table.csv')\n",
    "        self.assertIsInstance(country_names_with_asterisk, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(country_names_with_asterisk.shape, (3, 12))\n",
    "        column_values = set(country_names_with_asterisk['Combined_Key'].values)\n",
    "        self.assertTrue('Taiwan*' in column_values)\n",
    "        self.assertTrue('Crimea Republic*, Ukraine' in column_values)\n",
    "        self.assertTrue('Sevastopol*, Ukraine' in column_values)      \n",
    "    def test_02_remove_asterisk_in_dataframe(self):\n",
    "        asterisk_removed_dataframe = remove_asterisk_in_dataframe('UID_ISO_FIPS_LookUp_Table.csv')\n",
    "        self.assertIsInstance(asterisk_removed_dataframe, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(asterisk_removed_dataframe.shape, (4193, 12))\n",
    "        twn_ukr = asterisk_removed_dataframe[asterisk_removed_dataframe['UID'].isin([158, 80404, 80420])]\n",
    "        column_values = set(twn_ukr['Country_Region'].values)\n",
    "        self.assertTrue('Taiwan' in column_values)\n",
    "        column_values = set(twn_ukr['Province_State'].values)\n",
    "        self.assertTrue('Crimea Republic' in column_values)\n",
    "        self.assertTrue('Sevastopol' in column_values)\n",
    "        column_values = set(twn_ukr['Combined_Key'].values)\n",
    "        self.assertTrue('Taiwan' in column_values)\n",
    "        self.assertTrue('Crimea Republic, Ukraine' in column_values)\n",
    "        self.assertTrue('Sevastopol, Ukraine' in column_values) \n",
    "    def test_03_summarize_by_countries(self):\n",
    "        summary_by_countries = summarize_by_countries('05-25-2021.csv')\n",
    "        self.assertIsInstance(summary_by_countries, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(summary_by_countries.shape, (192, 3))\n",
    "    def test_04_summarize_by_countries_and_provinces(self):\n",
    "        summary_by_countries_and_provinces = summarize_by_countries_and_provinces('05-25-2021.csv')\n",
    "        self.assertIsInstance(summary_by_countries_and_provinces, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(summary_by_countries_and_provinces.shape, (593, 4))\n",
    "    def test_05_calculate_death_rate_by_countries(self):\n",
    "        death_rate_by_countries = calculate_death_rate_by_countries('05-25-2021.csv')\n",
    "        self.assertIsInstance(death_rate_by_countries, pd.core.series.Series)\n",
    "        self.assertEqual(death_rate_by_countries.size, 192)\n",
    "        ser_index = death_rate_by_countries.index\n",
    "        self.assertTrue('Vanuatu' in ser_index)\n",
    "        self.assertTrue('MS Zaandam' in ser_index)\n",
    "        self.assertTrue('Yemen' in ser_index)\n",
    "        self.assertTrue('Mexico' in ser_index)\n",
    "        self.assertTrue('Sudan' in ser_index)\n",
    "        ser_values = death_rate_by_countries.values\n",
    "        self.assertIsInstance(ser_values[0], np.float)\n",
    "    def test_06_calculate_confirmed_rate_by_countries(self):\n",
    "        confirmed_rate_by_countries = calculate_confirmed_rate_by_countries()\n",
    "        self.assertIsInstance(confirmed_rate_by_countries, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(confirmed_rate_by_countries.shape, (192, 3))\n",
    "        df_index = confirmed_rate_by_countries.index\n",
    "        self.assertTrue('Andorra' in df_index)\n",
    "        self.assertTrue('Montenegro' in df_index)\n",
    "        self.assertTrue('Czechia' in df_index)\n",
    "        df_columns = confirmed_rate_by_countries.columns\n",
    "        self.assertTrue('Confirmed' in df_columns)\n",
    "        self.assertTrue('Population' in df_columns)\n",
    "        self.assertTrue('Confirmed_Rate' in df_columns)\n",
    "        df_values = confirmed_rate_by_countries['Confirmed_Rate'].values\n",
    "        self.assertIsInstance(df_values[0], np.float)\n",
    "    def test_07_transpose_time_series(self):\n",
    "        transposed_time_series = transpose_time_series('time_series_covid19_confirmed_global.csv')\n",
    "        self.assertIsInstance(transposed_time_series, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(transposed_time_series.shape, (134750, 4))\n",
    "    def test_08_summarize_time_series(self):\n",
    "        summarized_time_series = summarize_time_series()\n",
    "        self.assertIsInstance(summarized_time_series, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(summarized_time_series.shape, (94080, 4))\n",
    "    def test_09_calculate_daily_cases_of_taiwan(self):\n",
    "        daily_cases_of_taiwan = calculate_daily_cases_of_taiwan()\n",
    "        self.assertIsInstance(daily_cases_of_taiwan, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(daily_cases_of_taiwan.shape, (490, 5))\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestHomeworkSix)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "test_results = runner.run(suite)\n",
    "number_of_failures = len(test_results.failures)\n",
    "number_of_errors = len(test_results.errors)\n",
    "number_of_test_runs = test_results.testsRun\n",
    "number_of_successes = number_of_test_runs - (number_of_failures + number_of_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've got 10 successes among 10 questions.\n"
     ]
    }
   ],
   "source": [
    "print(\"You've got {} successes among {} questions.\".format(number_of_successes, number_of_test_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
